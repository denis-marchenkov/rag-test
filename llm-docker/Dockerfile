# TEMPLATE: Replace with the actual image and serving command for Qwen2.5-coder-1.5b-instruct
FROM your-qwen2.5-coder-1.5b-instruct-image:latest

# Expose the port your LLM API will use
EXPOSE 9000

# Set environment variables or copy model files as needed
# ENV ...
# COPY ...

# Start the LLM server (replace with actual command)
CMD ["python", "serve.py"] 